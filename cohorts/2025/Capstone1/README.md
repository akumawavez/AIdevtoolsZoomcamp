# ðŸ§  AI-Powered Aptitude Testing Platform

> A comprehensive solution for automating technical aptitude tests using AI, designed to streamline the hiring process for recruiters and candidates.

## 1. Problem Description

### The Pain Point
Hiring for technical roles is a bottleneck. Recruiters spend countless hours manually creating test questions, reviewing code submissions, and scheduling interviews. Existing platforms are often rigid, expensive, or lack deep insight into a candidate's thought process.

### The Solution
This project, **Capstone 1**, builds an **AI-Powered Aptitude Testing Platform** that automates the lifecycle of technical assessments.
*   **For Recruiters**: Generates tailored technical tests (MCQs, Coding, Logic) instantly based on role descriptions.
*   **For Candidates**: Provides a clean, distraction-free interface for taking tests.
*   **For Evaluation**: Uses an AI Agent to grade submissions, analyze code quality, and provide detailed feedback, significantly reducing time-to-hire.

## 2. AI System Development (Agentic Workflow & MCP)

This project leverages advanced AI patterns to go beyond simple text generation.

*   **AI-Assisted Development**: The system was built using agentic coding workflows (e.g., Cursor/Windsurf) to accelerate boilerplate generation and logic implementation.
*   **Model Context Protocol (MCP)**:
    *   **Evaluation Agent**: checks candidate code against test cases by accessing the file system sandbox securely via MCP.
    *   **Context Awareness**: The AI evaluator uses MCP to read the specific "Scoring Rubric" and "Test Specifications" directly from the repository to ensure consistent grading standards.
*   **Tools**: OpenAI (GPT-4o) / Anthropic (Claude 3.5 Sonnet) are used for the reasoning engine.

## 3. Technologies and System Architecture

The application follows a modern, containerized microservices architecture.

### Tech Stack
| Component | Technology | Description |
| :--- | :--- | :--- |
| **Frontend** | React + TypeScript | Robust, type-safe UI for candidates and dashboards. |
| **Styling** | Tailwind CSS | Utility-first CSS for responsive design. |
| **Backend** | FastAPI (Python) | High-performance async API framework. |
| **Database** | PostgreSQL | Relational database for storage reliability. |
| **AI Engine** | LangChain / OpenAI API | Orchestration for AI generation and evaluation. |
| **DevOps** | Docker & Docker Compose | Containerization for consistent environments. |

### Architecture Overview
1.  **Client**: React SPA communicating via REST API.
2.  **API Gateway / Backend**: FastAPI service handling auth, test management, and AI orchestration.
3.  **Data Layer**: PostgreSQL storing Users, Tests, Questions, and Submissions.
4.  **AI Worker**: Background tasks handling long-running AI generation and evaluation processes.

## 4. Implementation Details

### Frontend Implementation
*   **Structure**: Modular component design (e.g., `TestTaker`, `Dashboard`, `ResultCard`).
*   **State Management**: React Query / Context API for managing server state and user sessions.
*   **Communication**: Centralized API service layer interacting with the Backend endpoints.

### API Contract & Specifications
*   The backend works off a strict **OpenAPI Specification** (auto-generated by FastAPI at `/docs`).
*   Frontend clients are generated or typed against this spec to ensure type safety across the stack.

### Backend Implementation
*   **Pattern**: Adheres to Clean Architecture principles (Router -> Controller -> Service -> Repository).
*   **Validation**: Pydantic models ensure data integrity for all inputs and outputs.
*   **Queuing**: Uses background tasks for AI processing to keep the API responsive.

## 5. Infrastructure & Database

### Database Integration
*   The system uses **PostgreSQL**.
*   **ORM**: SQLAlchemy / SQLModel for Pythonic database interactions.
*   **Migrations**: Alembic handles schema changes and version control for the database.

### Containerization
*   The entire stack is containerized.
*   `Dockerfile` for Backend and Frontend.
*   `docker-compose.yml` orchestrates the services (API, DB, Frontend) and networking.

### CI/CD Pipeline
*   **CI**: GitHub Actions triggers on every push to run:
    *   Linting (Ruff/Eslint).
    *   Unit Tests (Pytest/Jest).
*   **CD**: (Planned) Automated deployment to cloud provider (e.g., AWS/Render) upon merger to `main`.

## 6. How to Run (Reproducibility)

Follow these steps to set up the project locally.

### Prerequisites
*   [Docker Desktop](https://www.docker.com/products/docker-desktop/) installed and running.
*   [Git](https://git-scm.com/) installed.
*   OpenAI / Anthropic API Key.

### Installation Steps

1.  **Clone the repository**
    ```bash
    git clone <repo-url>
    cd Capstone1
    ```

2.  **Environment Setup**
    Create a `.env` file in the root directory:
    ```bash
    cp .env.example .env
    # Edit .env and add your API keys
    # OPENAI_API_KEY=sk-...
    # DATABASE_URL=postgresql://user:password@db:5432/aptitude_test
    ```

3.  **Run with Docker Compose**
    ```bash
    docker-compose up --build
    ```

4.  **Access the Application**
    *   **Frontend**: `http://localhost:3000`
    *   **Backend API Docs**: `http://localhost:8000/docs`

### Testing
To run the integration tests:
```bash
docker-compose run backend pytest
```

---
*Built for the AI Engineering Zoomcamp 2025 Capstone Project.*